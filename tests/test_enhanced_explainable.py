"""Test enhanced explainable retrieval features"""
import numpy as np
import sys
import os

# Add parent directory to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from cad_vectordb.core.retrieval import TwoStageRetrieval, macro_distance
from cad_vectordb.core.feature import extract_feature
from cad_vectordb.utils.visualization import generate_html_visualization
import faiss


def create_mock_data():
    """Create mock data for testing"""
    # Create mock vectors
    np.random.seed(42)
    n_samples = 50
    seq_len = 7
    
    vectors = []
    ids = []
    metadata = []
    
    for i in range(n_samples):
        # Create mock CAD vectors (seq_len, 33)
        vec = np.random.randn(seq_len, 33).astype('float32')
        vec[:, 0] = np.random.randint(0, 10, seq_len)  # Commands
        vectors.append(vec)
        ids.append(f'test_{i:04d}.h5')
        metadata.append({
            'id': f'test_{i:04d}.h5',
            'file_path': f'test_{i:04d}.h5',
            'subset': f'{i//10:04d}',
            'seq_len': seq_len
        })
    
    return vectors, ids, metadata


def test_enhanced_explanation():
    """Test enhanced explanation features"""
    print('='*70)
    print('æµ‹è¯•å¢å¼ºçš„å¯è§£é‡Šæ£€ç´¢åŠŸèƒ½ | Testing Enhanced Explainable Retrieval')
    print('='*70)
    
    # Create mock data
    print('\n1. åˆ›å»ºæµ‹è¯•æ•°æ®...')
    vectors, ids, metadata = create_mock_data()
    
    # Extract features and build index
    print('2. æ„å»ºç´¢å¼•...')
    features = np.array([extract_feature(v) for v in vectors], dtype='float32')
    
    # Build FAISS index
    d = features.shape[1]
    index = faiss.IndexFlatL2(d)
    index.add(features)
    
    # Create retrieval system
    retrieval = TwoStageRetrieval(index, ids, metadata)
    
    # Monkey patch _load_macro_vec to use our mock data
    def mock_load_macro_vec(file_path):
        idx = ids.index(file_path) if file_path in ids else 0
        return vectors[idx]
    retrieval._load_macro_vec = mock_load_macro_vec
    
    # Test query
    print('3. æ‰§è¡Œå¯è§£é‡Šæ£€ç´¢...')
    query_vec = vectors[0]  # Use first vector as query
    query_path = ids[0]
    
    results, explanation = retrieval.search(
        query_vec,
        query_path,
        k=5,
        stage1_topn=20,
        fusion_method='weighted',
        alpha=0.6,
        beta=0.4,
        explainable=True
    )
    
    print(f'\nâœ… è¿”å› {len(results)} ä¸ªç»“æœ')
    
    # Verify explanation structure
    print('\n4. éªŒè¯è§£é‡Šç»“æ„...')
    required_fields = [
        'top_match', 'fusion_method', 'stage1_similarity', 'stage2_similarity',
        'final_score', 'stage1_quality', 'stage2_quality',
        'stage1_interpretation', 'stage2_interpretation',
        'match_analysis', 'confidence', 'recommendations', 'feature_analysis'
    ]
    
    for field in required_fields:
        assert field in explanation, f"âŒ ç¼ºå°‘å­—æ®µ: {field}"
    print('âœ… æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½å­˜åœ¨')
    
    # Display detailed explanation
    print('\n' + '='*70)
    print('è¯¦ç»†è§£é‡Š | Detailed Explanation')
    print('='*70)
    
    print(f'\nğŸ¯ æœ€ä½³åŒ¹é…: {explanation["top_match"]["id"]}')
    print(f'   æœ€ç»ˆå¾—åˆ†: {explanation["final_score"]:.4f}')
    print(f'   èåˆæ–¹æ³•: {explanation["fusion_method"]}')
    
    print(f'\nğŸ“Š ç›¸ä¼¼åº¦åˆ†è§£:')
    print(f'   Stage 1: {explanation["stage1_similarity"]:.4f} ({explanation["stage1_quality"]})')
    print(f'   è§£é‡Š: {explanation["stage1_interpretation"]}')
    print(f'   Stage 2: {explanation["stage2_similarity"]:.4f} ({explanation["stage2_quality"]})')
    print(f'   è§£é‡Š: {explanation["stage2_interpretation"]}')
    
    if 'contributions' in explanation:
        contrib = explanation['contributions']
        print(f'\nğŸ“ˆ è´¡çŒ®åˆ†æ:')
        print(f'   Stage 1: {contrib["stage1_percentage"]:.1f}% (æƒé‡: {contrib["stage1_weight"]})')
        print(f'   Stage 2: {contrib["stage2_percentage"]:.1f}% (æƒé‡: {contrib["stage2_weight"]})')
    
    analysis = explanation['match_analysis']
    print(f'\nğŸ¯ åŒ¹é…åˆ†æ:')
    print(f'   ç±»å‹: {analysis["match_type"]}')
    print(f'   æè¿°: {analysis["description"]}')
    print(f'   ä¸€è‡´æ€§: {analysis["consistency"]} (å·®å¼‚: {analysis["similarity_difference"]:.4f})')
    
    confidence = explanation['confidence']
    print(f'\nğŸšï¸ ç½®ä¿¡åº¦è¯„ä¼°:')
    print(f'   å¾—åˆ†: {confidence["score"]:.4f}')
    print(f'   çº§åˆ«: {confidence["level"]}')
    print(f'   æè¿°: {confidence["description"]}')
    print(f'   å¯é æ€§: {confidence["reliability"]}')
    
    feat = explanation['feature_analysis']
    print(f'\nğŸ”¬ ç‰¹å¾å‘é‡åˆ†æ:')
    print(f'   ä½™å¼¦ç›¸ä¼¼åº¦: {feat["cosine_similarity"]:.4f}')
    print(f'   L2è·ç¦»: {feat["l2_distance"]:.4f}')
    print(f'   å¹³å‡å·®å¼‚: {feat["mean_absolute_difference"]:.4f}')
    print(f'   è§£é‡Š: {feat["vector_interpretation"]}')
    
    print(f'\n   å·®å¼‚æœ€å¤§çš„3ä¸ªç»´åº¦:')
    for dim in feat['top_divergent_dims'][:3]:
        print(f'     ç»´åº¦ {dim["dimension"]}: æŸ¥è¯¢={dim["query_value"]:.4f}, ç»“æœ={dim["result_value"]:.4f}, å·®={dim["difference"]:.4f}')
    
    print(f'\nğŸ’¡ æ™ºèƒ½æ¨è ({len(explanation["recommendations"])} æ¡):')
    for i, rec in enumerate(explanation['recommendations'], 1):
        print(f'   {i}. {rec}')
    
    # Test visualization
    print('\n5. æµ‹è¯•HTMLå¯è§†åŒ–ç”Ÿæˆ...')
    output_file = '/tmp/test_explanation.html'
    try:
        # Add explanation to result for visualization
        results[0]['explanation'] = explanation
        
        generate_html_visualization(
            results[:3],
            query_path=query_path,
            output_file=output_file
        )
        
        # Check file size
        import os
        file_size = os.path.getsize(output_file)
        print(f'âœ… HTMLæ–‡ä»¶å·²ç”Ÿæˆ: {output_file} ({file_size} bytes)')
        
        # Basic content validation
        with open(output_file, 'r', encoding='utf-8') as f:
            content = f.read()
            assert 'å¯è§£é‡Šæ£€ç´¢ç»“æœ' in content
            assert 'ç›¸ä¼¼åº¦åˆ†è§£' in content
            assert 'åŒ¹é…åˆ†æ' in content
            assert 'ç½®ä¿¡åº¦è¯„ä¼°' in content
            assert 'ç‰¹å¾å‘é‡åˆ†æ' in content
            assert 'æ™ºèƒ½æ¨è' in content
        print('âœ… HTMLå†…å®¹éªŒè¯é€šè¿‡')
        
    except Exception as e:
        print(f'âŒ å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}')
        raise
    
    print('\n' + '='*70)
    print('âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡! å¢å¼ºçš„å¯è§£é‡Šæ£€ç´¢åŠŸèƒ½æ­£å¸¸å·¥ä½œ')
    print('='*70)
    
    return True


if __name__ == '__main__':
    test_enhanced_explanation()
